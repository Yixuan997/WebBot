"""
@Projectï¼šWebBot
@File   ï¼šworkflow.py
@IDE    ï¼šPyCharm
@Author ï¼šæ¨é€¸è½©
@Date   ï¼š2025/12/21
"""

import json
import os

from flask import render_template, request, flash, redirect, url_for, jsonify, g

from Core.logging.file_logger import log_info, log_error
from Core.workflow.registry import NodeRegistry
from Models import db
from Models.SQL.Workflow import Workflow
from utils.page_utils import adapt_pagination


def _clear_workflow_cache():
    """æ¸…é™¤å¹¶é‡è½½å·¥ä½œæµç¼“å­˜"""
    try:
        from Core.workflow.cache import workflow_cache
        from flask import current_app
        workflow_cache.reload()
    except Exception as e:
        log_error(0, f"é‡è½½å·¥ä½œæµç¼“å­˜å¤±è´¥: {e}", "WORKFLOW_CACHE_RELOAD_ERROR", error=str(e))


def _get_available_nodes() -> list[dict]:
    """è·å–æ‰€æœ‰å¯ç”¨çš„å·¥ä½œæµèŠ‚ç‚¹
    
    Returns:
        list[dict]: èŠ‚ç‚¹ä¿¡æ¯åˆ—è¡¨
    """
    available_nodes = []

    for node_type, node_class in NodeRegistry.list_all().items():
        if node_class:
            # è·å– config_schemaï¼šæ”¯æŒé™æ€å±æ€§å’Œ @property åŠ¨æ€å±æ€§
            config_schema = []
            try:
                # å°è¯•é€šè¿‡å®ä¾‹åŒ–è·å–ï¼ˆæ”¯æŒ @propertyï¼‰
                temp_instance = node_class({})
                config_schema = getattr(temp_instance, 'config_schema', [])
            except Exception:
                # å›é€€åˆ°ç±»å±æ€§
                config_schema = getattr(node_class, 'config_schema', [])

            node_info = {
                'type': node_type,
                'name': getattr(node_class, 'name', node_type),
                'description': getattr(node_class, 'description', ''),
                'category': getattr(node_class, 'category', 'core'),
                'icon': getattr(node_class, 'icon', 'ğŸ“¦'),
                'config_schema': config_schema,
                'inputs': getattr(node_class, 'inputs', []),
                'outputs': getattr(node_class, 'outputs', [])
            }
            available_nodes.append(node_info)

    return available_nodes


def workflow_list():
    """å·¥ä½œæµåˆ—è¡¨é¡µé¢"""
    try:
        # è·å–åˆ†é¡µå’Œæœç´¢å‚æ•°
        page = request.args.get('page', 1, type=int)
        search = request.args.get('search', '', type=str).strip()
        per_page = 10

        # æ„å»ºæŸ¥è¯¢
        query = Workflow.query

        # æœç´¢è¿‡æ»¤
        if search:
            query = query.filter(Workflow.name.ilike(f'%{search}%'))

        # æŒ‰ ID å€’åºï¼ˆæœ€æ–°åˆ›å»ºçš„åœ¨å‰ï¼‰
        pagination = query.order_by(
            Workflow.id.desc()
        ).paginate(page=page, per_page=per_page, error_out=False)

        workflows = pagination.items
        
        # ä½¿ç”¨æ™ºèƒ½åˆ†é¡µ
        page_numbers = adapt_pagination(pagination)

        return render_template('admin/workflow/list.html',
                               workflows=workflows,
                               pagination=pagination,
                               page_numbers=page_numbers,
                               search=search,
                               current_page=page)

    except Exception as e:
        log_error(0, f"è·å–å·¥ä½œæµåˆ—è¡¨å¤±è´¥: {e}", "WORKFLOW_LIST_ERROR", error=str(e))
        flash('è·å–å·¥ä½œæµåˆ—è¡¨å¤±è´¥', 'error')
        return render_template('admin/workflow/list.html', workflows=[], pagination=None)


def workflow_create():
    """åˆ›å»ºå·¥ä½œæµ"""
    from Models import Bot
    
    if request.method == 'GET':
        # æ˜¾ç¤ºåˆ›å»ºè¡¨å•ï¼Œä¼ é€’æœºå™¨äººåˆ—è¡¨ç”¨äºå®šæ—¶è§¦å‘é…ç½®
        bots = Bot.query.filter_by(is_active=True).all()
        return render_template('admin/workflow/create.html', bots=bots)

    # POST: å¤„ç†åˆ›å»º
    try:
        name = request.form.get('name', '').strip()
        description = request.form.get('description', '').strip()
        enabled = request.form.get('enabled', 'false') == 'true'
        priority = int(request.form.get('priority', 100))
        trigger_type = request.form.get('trigger_type', 'message')
        
        # è§£æåè®®é™åˆ¶
        protocols_str = request.form.get('protocols', '[]')
        try:
            protocols = json.loads(protocols_str)
        except json.JSONDecodeError:
            protocols = []

        # éªŒè¯å¿…å¡«å­—æ®µ
        if not name:
            return jsonify({'success': False, 'message': 'å·¥ä½œæµåç§°ä¸èƒ½ä¸ºç©º'})

        # æ£€æŸ¥åç§°æ˜¯å¦å·²å­˜åœ¨
        existing = Workflow.query.filter_by(name=name).first()
        if existing:
            return jsonify({'success': False, 'message': f'å·¥ä½œæµåç§°"{name}"å·²å­˜åœ¨'})

        # åˆ›å»ºé»˜è®¤å·¥ä½œæµé…ç½®ï¼ˆåŒ…å«startå’ŒendèŠ‚ç‚¹ï¼‰
        default_config = {
            'name': name,
            'description': description,
            'protocols': protocols,
            'allow_continue': True,  # é»˜è®¤å…è®¸ç»§ç»­æ‰§è¡Œåç»­å·¥ä½œæµ
            'trigger_type': trigger_type,
            'workflow': [
                {
                    'id': 'start',
                    'type': 'start',
                    'config': {}
                },
                {
                    'id': 'end',
                    'type': 'end',
                    'config': {
                        'allow_continue': True  # é»˜è®¤å…è®¸ç»§ç»­æ‰§è¡Œ
                    }
                }
            ]
        }
        
        # å¦‚æœæ˜¯å®šæ—¶è§¦å‘ï¼Œæ·»åŠ è°ƒåº¦é…ç½®
        if trigger_type == 'schedule':
            schedule_type = request.form.get('schedule_type', 'cron')
            default_config['schedule'] = {
                'type': schedule_type
            }
            if schedule_type == 'cron':
                default_config['schedule']['cron'] = request.form.get('schedule_cron', '0 8 * * *')
            else:
                default_config['schedule']['interval_minutes'] = int(request.form.get('schedule_interval', 60))

        # åˆ›å»ºå·¥ä½œæµ
        creator_id = g.user.id if hasattr(g, 'user') else None
        workflow = Workflow.create_from_config(
            name=name,
            description=description,
            config=default_config,
            creator_id=creator_id,
            enabled=enabled,
            priority=priority
        )

        log_info(0, f"åˆ›å»ºå·¥ä½œæµ: {name}", "WORKFLOW_CREATE",
                 workflow_id=workflow.id, creator_id=creator_id, trigger_type=trigger_type)

        _clear_workflow_cache()

        flash(f'å·¥ä½œæµ {name} åˆ›å»ºæˆåŠŸ', 'success')
        return redirect(url_for('Admin.workflow_edit', workflow_id=workflow.id))

    except Exception as e:
        log_error(0, f"åˆ›å»ºå·¥ä½œæµå¤±è´¥: {e}", "WORKFLOW_CREATE_ERROR", error=str(e))
        flash(f'åˆ›å»ºå¤±è´¥: {str(e)}', 'danger')
        return redirect(url_for('Admin.workflow_create'))


def workflow_edit(workflow_id):
    """ç¼–è¾‘å·¥ä½œæµ"""
    workflow = Workflow.query.get_or_404(workflow_id)

    if request.method == 'GET':
        # æ˜¾ç¤ºç¼–è¾‘è¡¨å•
        available_nodes = _get_available_nodes()
        config = workflow.get_config()

        return render_template('admin/workflow/edit.html',
                               workflow=workflow,
                               config=config,
                               available_nodes=available_nodes)

    # POST: å¤„ç†æ›´æ–°ï¼ˆä»…æ›´æ–°å·¥ä½œæµèŠ‚ç‚¹ï¼‰
    try:
        # è·å–å·¥ä½œæµèŠ‚ç‚¹é…ç½®ï¼ˆJSONï¼‰
        workflow_data = request.form.get('workflow_data', '{}')
        try:
            workflow_config = json.loads(workflow_data)
        except json.JSONDecodeError:
            return jsonify({'success': False, 'message': 'å·¥ä½œæµé…ç½®æ ¼å¼é”™è¯¯'})

        # ä» EndèŠ‚ç‚¹é…ç½®ä¸­æå–allow_continueæ ‡å¿—
        allow_continue = True  # é»˜è®¤å€¼
        workflow_nodes = workflow_config.get('workflow', [])
        for node in workflow_nodes:
            if node.get('type') == 'end':
                allow_continue = node.get('config', {}).get('allow_continue', True)
                break

        config = workflow.get_config()
        config['allow_continue'] = allow_continue
        config['workflow'] = workflow_nodes
        config['protocols'] = workflow_config.get('protocols', config.get('protocols', []))

        workflow.update_config(config)

        log_info(0, f"æ›´æ–°å·¥ä½œæµèŠ‚ç‚¹: {workflow.name}", "WORKFLOW_UPDATE_NODES", 
                 workflow_id=workflow_id)

        _clear_workflow_cache()

        flash('å·¥ä½œæµèŠ‚ç‚¹æ›´æ–°æˆåŠŸ', 'success')
        return redirect(url_for('Admin.workflow_detail', workflow_id=workflow_id))

    except Exception as e:
        log_error(0, f"æ›´æ–°å·¥ä½œæµå¤±è´¥: {e}", "WORKFLOW_UPDATE_ERROR",
                  workflow_id=workflow_id, error=str(e))
        flash(f'æ›´æ–°å¤±è´¥: {str(e)}', 'danger')
        return redirect(url_for('Admin.workflow_edit', workflow_id=workflow_id))


def workflow_delete(workflow_id):
    """åˆ é™¤å·¥ä½œæµ"""
    try:
        workflow = Workflow.query.get_or_404(workflow_id)
        workflow_name = workflow.name

        db.session.delete(workflow)
        db.session.commit()

        log_info(0, f"åˆ é™¤å·¥ä½œæµ: {workflow_name}", "WORKFLOW_DELETE", workflow_id=workflow_id)

        _clear_workflow_cache()

        flash(f'å·¥ä½œæµ {workflow_name} åˆ é™¤æˆåŠŸ', 'success')

    except Exception as e:
        log_error(0, f"åˆ é™¤å·¥ä½œæµå¤±è´¥: {e}", "WORKFLOW_DELETE_ERROR",
                  workflow_id=workflow_id, error=str(e))
        db.session.rollback()
        flash(f'åˆ é™¤å·¥ä½œæµå¤±è´¥: {str(e)}', 'danger')

    return redirect(url_for('Admin.workflow_list'))


def workflow_toggle(workflow_id):
    """åˆ‡æ¢å·¥ä½œæµå¯ç”¨çŠ¶æ€"""
    try:
        workflow = Workflow.query.get_or_404(workflow_id)
        workflow.toggle_enabled()

        status = 'å¯ç”¨' if workflow.enabled else 'ç¦ç”¨'
        log_info(0, f"{status}å·¥ä½œæµ: {workflow.name}", "WORKFLOW_TOGGLE",
                 workflow_id=workflow_id, enabled=workflow.enabled)

        _clear_workflow_cache()

        flash(f'å·¥ä½œæµ {workflow.name} å·²{status}', 'success')

    except Exception as e:
        log_error(0, f"åˆ‡æ¢å·¥ä½œæµçŠ¶æ€å¤±è´¥: {e}", "WORKFLOW_TOGGLE_ERROR",
                  workflow_id=workflow_id, error=str(e))
        flash(f'æ“ä½œå¤±è´¥: {str(e)}', 'danger')

    return redirect(url_for('Admin.workflow_list'))


def workflow_detail(workflow_id):
    """å·¥ä½œæµè¯¦æƒ…é¡µé¢"""
    try:
        workflow = Workflow.query.get_or_404(workflow_id)
        config = workflow.get_config()

        return render_template('admin/workflow/detail.html',
                               workflow=workflow,
                               config=config)

    except Exception as e:
        log_error(0, f"è·å–å·¥ä½œæµè¯¦æƒ…å¤±è´¥: {e}", "WORKFLOW_DETAIL_ERROR",
                  workflow_id=workflow_id, error=str(e))
        flash('è·å–å·¥ä½œæµè¯¦æƒ…å¤±è´¥', 'error')
        return redirect(url_for('Admin.workflow_list'))


def workflow_update_basic(workflow_id):
    """æ›´æ–°å·¥ä½œæµåŸºæœ¬ä¿¡æ¯ï¼ˆåç§°ã€æè¿°ã€ä¼˜å…ˆçº§ã€å®šæ—¶é…ç½®ï¼‰"""
    try:
        workflow = Workflow.query.get_or_404(workflow_id)
        data = json.loads(request.form.get('data', '{}'))
        
        name = data.get('name', '').strip()
        description = data.get('description', '').strip()
        priority = int(data.get('priority', 100))
        
        # éªŒè¯åç§°
        if not name:
            flash('å·¥ä½œæµåç§°ä¸èƒ½ä¸ºç©º', 'warning')
            return redirect(url_for('Admin.workflow_detail', workflow_id=workflow_id))
        
        # æ£€æŸ¥åç§°æ˜¯å¦ä¸å…¶ä»–å·¥ä½œæµå†²çª
        existing = Workflow.query.filter(
            Workflow.name == name,
            Workflow.id != workflow_id
        ).first()
        if existing:
            flash(f'å·¥ä½œæµåç§°"{name}"å·²è¢«ä½¿ç”¨', 'warning')
            return redirect(url_for('Admin.workflow_detail', workflow_id=workflow_id))
        
        # æ›´æ–°åŸºæœ¬å­—æ®µ
        workflow.name = name
        workflow.description = description
        workflow.priority = priority
        
        # æ›´æ–° config ä¸­çš„åç§°å’Œæè¿°
        config = workflow.get_config()
        config['name'] = name
        config['description'] = description
        
        # æ›´æ–°åè®®é™åˆ¶
        protocols = data.get('protocols', [])
        config['protocols'] = protocols
        
        # å¤„ç†å®šæ—¶é…ç½®ï¼ˆä»…å®šæ—¶è§¦å‘ç±»å‹ï¼‰
        if config.get('trigger_type') == 'schedule':
            schedule_type = data.get('schedule_type', 'cron')
            config['schedule'] = {'type': schedule_type}
            
            if schedule_type == 'cron':
                config['schedule']['cron'] = data.get('schedule_cron', '0 8 * * *')
            else:
                config['schedule']['interval_minutes'] = int(data.get('schedule_interval', 60))
        
        workflow.update_config(config)
        
        log_info(0, f"æ›´æ–°å·¥ä½œæµåŸºæœ¬ä¿¡æ¯: {name}", "WORKFLOW_UPDATE_BASIC",
                 workflow_id=workflow_id)
        
        _clear_workflow_cache()
        
        flash('åŸºæœ¬ä¿¡æ¯ä¿å­˜æˆåŠŸ', 'success')
        return redirect(url_for('Admin.workflow_detail', workflow_id=workflow_id))
        
    except Exception as e:
        log_error(0, f"æ›´æ–°å·¥ä½œæµåŸºæœ¬ä¿¡æ¯å¤±è´¥: {e}", "WORKFLOW_UPDATE_BASIC_ERROR",
                  workflow_id=workflow_id, error=str(e))
        flash(f'ä¿å­˜å¤±è´¥: {str(e)}', 'danger')
        return redirect(url_for('Admin.workflow_detail', workflow_id=workflow_id))


def _parse_snippet_metadata(snippet_code: str) -> dict:
    """è§£æä»£ç ç‰‡æ®µçš„å…ƒæ•°æ®
    
    Args:
        snippet_code: Pythonä»£ç ç‰‡æ®µ
        
    Returns:
        dict: åŒ…å«name, description, authorç­‰å…ƒæ•°æ®
    """
    metadata = {
        'name': 'æœªå‘½åç‰‡æ®µ',
        'description': '',
        'author': '',
        'version': '1.0.0'
    }

    # ç®€å•çš„å…ƒæ•°æ®è§£æï¼ˆä»æ³¨é‡Šä¸­æå–ï¼‰
    lines = snippet_code.split('\n')
    for line in lines[:10]:  # åªæ£€æŸ¥å‰10è¡Œ
        line = line.strip()
        if line.startswith('#'):
            if 'name:' in line.lower():
                metadata['name'] = line.split(':', 1)[1].strip()
            elif 'desc' in line.lower():
                metadata['description'] = line.split(':', 1)[1].strip()
            elif 'author:' in line.lower():
                metadata['author'] = line.split(':', 1)[1].strip()

    return metadata


def workflow_reload_cache():
    """æ‰‹åŠ¨é‡è½½å·¥ä½œæµç¼“å­˜"""
    try:
        from Core.workflow.cache import workflow_cache
        from flask import current_app

        count = workflow_cache.reload()

        log_info(0, f"æ‰‹åŠ¨é‡è½½å·¥ä½œæµç¼“å­˜", "WORKFLOW_CACHE_MANUAL_RELOAD", count=count)

        # è·å–ç¼“å­˜ç»Ÿè®¡ä¿¡æ¯
        stats = workflow_cache.get_stats()

        return jsonify({
            'success': True,
            'message': f'ç¼“å­˜å·²é‡è½½ï¼Œå…± {count} ä¸ªå·¥ä½œæµ',
            'stats': stats
        })

    except Exception as e:
        log_error(0, f"é‡è½½å·¥ä½œæµç¼“å­˜å¤±è´¥: {e}", "WORKFLOW_CACHE_RELOAD_ERROR", error=str(e))
        return jsonify({
            'success': False,
            'message': f'é‡è½½å¤±è´¥: {str(e)}'
        })


def workflow_import():
    """å¯¼å…¥å·¥ä½œæµï¼ˆæ”¯æŒ ZIP æ ¼å¼ï¼ŒåŒ…å«ä»£ç ç‰‡æ®µå’Œæ¸²æŸ“æ¨¡æ¿ï¼‰"""
    import zipfile
    import io

    if 'file' not in request.files:
        return jsonify({'success': False, 'message': 'æœªé€‰æ‹©æ–‡ä»¶'})

    file = request.files['file']
    if file.filename == '':
        return jsonify({'success': False, 'message': 'æœªé€‰æ‹©æ–‡ä»¶'})

    # æ£€æŸ¥æ–‡ä»¶åç¼€
    if not file.filename.endswith('.workflow'):
        return jsonify({'success': False, 'message': 'æ–‡ä»¶æ ¼å¼ä¸æ­£ç¡®ï¼Œè¯·é€‰æ‹© .workflow æ–‡ä»¶'})

    try:
        file_content = file.read()
        base_dir = os.path.dirname(os.path.dirname(os.path.dirname(__file__)))

        # è§£å‹ ZIP
        try:
            zip_buffer = io.BytesIO(file_content)
            zf = zipfile.ZipFile(zip_buffer, 'r')
        except zipfile.BadZipFile:
            return jsonify({'success': False, 'message': 'æ–‡ä»¶æ ¼å¼é”™è¯¯ï¼Œä¸æ˜¯æœ‰æ•ˆçš„ ZIP æ–‡ä»¶'})

        with zf:
            # è¯»å–å·¥ä½œæµé…ç½®
            if 'workflow.json' not in zf.namelist():
                return jsonify({'success': False, 'message': 'æ–‡ä»¶ç¼ºå°‘ workflow.json'})

            data = json.loads(zf.read('workflow.json').decode('utf-8'))

            # æå–ä»£ç ç‰‡æ®µå’Œæ¨¡æ¿æ–‡ä»¶
            copied_files = []
            for name in zf.namelist():
                if name.startswith('Snippets/') and name != 'Snippets/':
                    target_path = os.path.join(base_dir, name)
                    os.makedirs(os.path.dirname(target_path), exist_ok=True)
                    content = zf.read(name)
                    if not os.path.exists(target_path):
                        with open(target_path, 'wb') as f:
                            f.write(content)
                        copied_files.append(name)
                elif name.startswith('Render/') and name != 'Render/':
                    target_path = os.path.join(base_dir, name)
                    os.makedirs(os.path.dirname(target_path), exist_ok=True)
                    content = zf.read(name)
                    if not os.path.exists(target_path):
                        with open(target_path, 'wb') as f:
                            f.write(content)
                        copied_files.append(name)

        # æ ¡éªŒæ ¼å¼
        if 'workflow' not in data:
            return jsonify({'success': False, 'message': 'æ–‡ä»¶æ ¼å¼é”™è¯¯ï¼Œç¼ºå°‘ workflow å­—æ®µ'})

        workflow_data = data['workflow']
        name = workflow_data.get('name', '')
        if not name:
            return jsonify({'success': False, 'message': 'å·¥ä½œæµåç§°ä¸èƒ½ä¸ºç©º'})

        config = workflow_data.get('config', {})
        if not config.get('workflow'):
            return jsonify({'success': False, 'message': 'å·¥ä½œæµé…ç½®ä¸å®Œæ•´'})

        # æ£€æŸ¥åç§°æ˜¯å¦å·²å­˜åœ¨
        original_name = name
        counter = 1
        while Workflow.query.filter_by(name=name).first():
            name = f"{original_name}_å¯¼å…¥{counter}"
            counter += 1

        # åˆ›å»ºå·¥ä½œæµ
        creator_id = g.user.id if hasattr(g, 'user') else None
        workflow = Workflow.create_from_config(
            name=name,
            description=config.get('description', ''),
            config=config,
            creator_id=creator_id,
            enabled=False,
            priority=workflow_data.get('priority', 100)
        )

        log_info(0, f"å¯¼å…¥å·¥ä½œæµ: {name}", "WORKFLOW_IMPORT",
                 workflow_id=workflow.id, original_name=original_name, copied_files=copied_files)

        _clear_workflow_cache()

        renamed = name != original_name
        message = 'å·¥ä½œæµå¯¼å…¥æˆåŠŸ'
        if renamed:
            message += f'ï¼ˆå·²é‡å‘½åä¸º"{name}"ï¼‰'
        if copied_files:
            message += f'ï¼Œå·²å¤åˆ¶ {len(copied_files)} ä¸ªæ–‡ä»¶'

        return jsonify({
            'success': True,
            'message': message,
            'workflow_id': workflow.id,
            'name': name,
            'renamed': renamed,
            'copied_files': copied_files
        })

    except json.JSONDecodeError:
        return jsonify({'success': False, 'message': 'æ–‡ä»¶å†…å®¹è§£æå¤±è´¥'})
    except Exception as e:
        log_error(0, f"å¯¼å…¥å·¥ä½œæµå¤±è´¥: {e}", "WORKFLOW_IMPORT_ERROR", error=str(e))
        return jsonify({'success': False, 'message': f'å¯¼å…¥å¤±è´¥: {str(e)}'})


def workflow_export(workflow_id):
    """å¯¼å‡ºå•ä¸ªå·¥ä½œæµï¼ˆZIP æ ¼å¼ï¼ŒåŒ…å«ä»£ç ç‰‡æ®µå’Œæ¸²æŸ“æ¨¡æ¿ï¼‰"""
    from flask import Response
    from datetime import datetime
    from urllib.parse import quote
    import zipfile
    import io

    try:
        workflow = Workflow.query.get_or_404(workflow_id)
        config = workflow.get_config()
        workflow_steps = config.get('workflow', [])

        # æ”¶é›†å¼•ç”¨çš„æ–‡ä»¶
        snippets = set()
        templates = set()
        for step in workflow_steps:
            step_config = step.get('config', {})
            if step.get('type') == 'python_snippet' and step_config.get('snippet_name'):
                snippets.add(step_config['snippet_name'])
            if step.get('type') == 'html_render' and step_config.get('template_path'):
                templates.add(step_config['template_path'])

        # æ„å»ºå¯¼å‡ºæ•°æ®
        export_data = {
            'version': '2.0',
            'export_time': datetime.now().isoformat(),
            'workflow': {
                'name': workflow.name,
                'priority': workflow.priority,
                'enabled': workflow.enabled,
                'config': config
            },
            'files': {
                'snippets': list(snippets),
                'templates': list(templates)
            }
        }

        # åˆ›å»º ZIP æ–‡ä»¶
        zip_buffer = io.BytesIO()
        base_dir = os.path.dirname(os.path.dirname(os.path.dirname(__file__)))

        with zipfile.ZipFile(zip_buffer, 'w', zipfile.ZIP_DEFLATED) as zf:
            # å†™å…¥å·¥ä½œæµé…ç½®
            zf.writestr('workflow.json', json.dumps(export_data, ensure_ascii=False, indent=2))

            # å†™å…¥ä»£ç ç‰‡æ®µ
            for snippet in snippets:
                snippet_path = os.path.join(base_dir, 'Snippets', snippet)
                if os.path.exists(snippet_path):
                    zf.write(snippet_path, f'Snippets/{snippet}')

            # å†™å…¥æ¸²æŸ“æ¨¡æ¿
            for template in templates:
                template_path = os.path.join(base_dir, 'Render', template)
                if os.path.exists(template_path):
                    zf.write(template_path, f'Render/{template}')

        zip_buffer.seek(0)

        # ç”Ÿæˆæ–‡ä»¶å
        safe_name = workflow.name.replace(' ', '_').replace('/', '_')
        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
        filename = f"{safe_name}_{timestamp}.workflow"
        encoded_filename = quote(filename)

        response = Response(
            zip_buffer.getvalue(),
            mimetype='application/zip',
            headers={
                'Content-Disposition': f"attachment; filename*=UTF-8''{encoded_filename}"
            }
        )

        log_info(0, f"å¯¼å‡ºå·¥ä½œæµ: {workflow.name}", "WORKFLOW_EXPORT",
                 workflow_id=workflow_id, snippets=list(snippets), templates=list(templates))

        return response

    except Exception as e:
        log_error(0, f"å¯¼å‡ºå·¥ä½œæµå¤±è´¥: {e}", "WORKFLOW_EXPORT_ERROR", workflow_id=workflow_id, error=str(e))
        return jsonify({'success': False, 'message': f'å¯¼å‡ºå¤±è´¥: {str(e)}'}), 500


def snippets_list():
    """ä»£ç ç‰‡æ®µåˆ—è¡¨"""
    import os

    try:
        snippets_dir = os.path.join(os.path.dirname(os.path.dirname(os.path.dirname(__file__))), 'Snippets')
        snippets = []

        # æ£€æŸ¥ç›®å½•æ˜¯å¦å­˜åœ¨
        if not os.path.exists(snippets_dir):
            return jsonify({
                'success': True,
                'snippets': []
            })

        # éå†ç›®å½•ä¸­çš„ .py æ–‡ä»¶
        for filename in os.listdir(snippets_dir):
            if filename.endswith('.py') and not filename.startswith('_'):
                filepath = os.path.join(snippets_dir, filename)

                # è¯»å–æ–‡ä»¶å†…å®¹
                try:
                    with open(filepath, 'r', encoding='utf-8') as f:
                        code = f.read()

                    # è§£æå…ƒæ•°æ®
                    metadata = _parse_snippet_metadata(code)

                    snippets.append({
                        'filename': filename,
                        'name': metadata.get('name', filename.replace('.py', '')),
                        'description': metadata.get('description', ''),
                        'author': metadata.get('author', ''),
                        'version': metadata.get('version', '1.0.0')
                    })
                except Exception as e:
                    log_error(0, f"è¯»å–ä»£ç ç‰‡æ®µå¤±è´¥: {filename}", "SNIPPET_READ_ERROR", error=str(e))
                    continue

        return jsonify({
            'success': True,
            'snippets': snippets
        })

    except Exception as e:
        log_error(0, f"è·å–ä»£ç ç‰‡æ®µåˆ—è¡¨å¤±è´¥: {e}", "SNIPPETS_LIST_ERROR", error=str(e))
        return jsonify({
            'success': False,
            'message': f'è·å–ä»£ç ç‰‡æ®µå¤±è´¥: {str(e)}',
            'snippets': []
        })


def workflow_debug_record(workflow_id):
    """è·å–æŒ‡å®šå·¥ä½œæµçš„è°ƒè¯•è®°å½•"""
    try:
        from Core.workflow.debug import get_debug_record
        
        record = get_debug_record(workflow_id)
        
        if record:
            return jsonify({
                'success': True,
                'record': record
            })
        else:
            return jsonify({
                'success': True,
                'record': None,
                'message': 'æš‚æ— è°ƒè¯•è®°å½•'
            })
            
    except Exception as e:
        log_error(0, f"è·å–å·¥ä½œæµè°ƒè¯•è®°å½•å¤±è´¥: {e}", "WORKFLOW_DEBUG_GET_ERROR",
                  workflow_id=workflow_id, error=str(e))
        return jsonify({
            'success': False,
            'message': f'è·å–è°ƒè¯•è®°å½•å¤±è´¥: {str(e)}'
        })


def workflow_debug_clear(workflow_id):
    """æ¸…é™¤æŒ‡å®šå·¥ä½œæµçš„è°ƒè¯•è®°å½•"""
    try:
        from Core.workflow.debug import clear_debug_record
        
        clear_debug_record(workflow_id)
        
        return jsonify({
            'success': True,
            'message': 'è°ƒè¯•è®°å½•å·²æ¸…é™¤'
        })
            
    except Exception as e:
        log_error(0, f"æ¸…é™¤å·¥ä½œæµè°ƒè¯•è®°å½•å¤±è´¥: {e}", "WORKFLOW_DEBUG_CLEAR_ERROR",
                  workflow_id=workflow_id, error=str(e))
        return jsonify({
            'success': False,
            'message': f'æ¸…é™¤è°ƒè¯•è®°å½•å¤±è´¥: {str(e)}'
        })
